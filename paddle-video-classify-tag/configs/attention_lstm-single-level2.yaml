MODEL:
    name: "AttentionLSTM"
    dataset: "YouTube-8M"  #Default, don't recommand to modify it
    bone_nework: None
    drop_rate: 0.5
    feature_names: ['rgb']  #rbg only, without audio
    feature_dims: [2048]
    embedding_size: 1024
    lstm_size: 512
    num_classes: 278
    topk: 20

TRAIN:
    epoch: 3
    learning_rate: 0.000125
    decay_epochs: [5]
    decay_gamma: 0.1
    weight_decay: 0.0008
    num_samples: 35952  # modify it according to the number samples of your dataset
    pretrain_base: None
    batch_size: 128
    use_gpu: True
    num_gpus: 1
    filelist: "data/level2_train.list"

VALID:
    batch_size: 128
    filelist: "data/level2_val.list"

TEST:
    batch_size: 128
    filelist: "data/level2_val.list"

INFER:
    batch_size: 1
    filelist: "data/level2_test.list"
